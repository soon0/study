## Data Warehouse란?
	• 데이터를 모아 둔 아주 큰 저장소
	• Enterprise Data Warehouse, EDW : 전사적 데이터 웨어하우스
	1. 일반적인 하둡의 사용처 = EDW아키텍처 보완영역
		a. 데이터 웨어하우스 오프로드
			i. 시스템에서 실행되는 일부 작업을 다른 시스템으로 이관하여 원 시스템의 부하를 줄이는 작업
		b. 데이터 웨어하우스 최적화 (Data warehouse Optimization)
	2. 하둡을 이용한 데이터 웨어하우스 오프로드(offload)의 영역
		a. ETL/ELT
			i. ETL : 추출 - 변환 - 정제
			ii. ELT : 추출 - 적재 - 변환
		b. 데이터 아카이빙
			• 과거 데이터 백업의 경우 외부 아카이브 시스템으로 옮기는 것 보다 하둡으로 이관하는 것이 효과적
		c. 탐색적 자료 분석 (Exploratory analysis)
			• EDW에 존재하지 않는 데이터를 분석할 때 이상적인 샌드박스(보호된 영역 내에서 프로그램을 동작하는 것) 제공
			• 구조화 되지 않거나, 단순히 데이터가 너무 커 EDW에 적재할 수 없는 경우도 쿼리 가능
	3. 전통적인 데이터 웨어하우스 아키텍처 구성요소
		• 계층 간 데이터의 이동 및 변환 작업은 데이터 통합(Data Integration, DI) 툴로 구현
		a. 원천 운영 시스템
			• 온라인 트랜잭션 처리(Online Transactional Processing, OLTP) 데이터베이스와 온라인 데이터 저장소
			• 실제로 높은 수준으로 정규화 되어있으며 인덱스가 많이 달려 있는 스키마 --> 단일 레코드 처리에 최적화
		b. 데이터 스테이징 영역
			•  ETL/ELT 처리 플렛폼으로 임시 저장 영역처림 사용
			• 원천 운영 시스템에서 데이터 추출 -> DW 적재 전 변환 수행 스테이징 영역으로 옮겨짐
			• 데이터 중복 제거, 데이터 정규화, 데이터 정제, 데이터 인리치먼트 등 포함
			• 고정된 아키텍처는 아님
			• 사용자는 데이터에 쿼리, 리포팅을 하기 위해 접근할 수 없음
		c. 데이터 웨어하우스
			• 사용자가 분석 & 리포팅을 할 수 있도록 만들어진 데이터 
			• 다수 레코드에 접근하는 데이터 분석을 목적으로 설계
			• 디멘셔널(diemensional, 차원) 스키마 사용 
		d. 데이터 분석/시각화 툴
	
## 데이터 웨어하우스 구축에 하둡 사용 
	1. 하둡의 장점
		a. 대용량 데이터를 효과적으로 병렬처리 --> SLA(Service Level Agreement, 서비스 수준 합의) 달성 가능
		b. 하둡으로 처리 이관 시 데이터 웨어하우스의 자원을 여유있게 활용 가능하도록 함
		c. DW에 없는 데이터를 탐색할 수 있는 샌드박스 제공
		d. DW 아키텍처를 확장 할 필요가 없어짐
		e. 반구조화/ 비구조화 데이터 처리 가능 --> 최종 리포트나 스키마를 바꿔야할 때 신속한 변경 가능
	2. 하둡 데이터 웨어하우스 아키텍처
	
		○ 원천운영 시스템 및 로그/기타
			• 원천운영시스템은 스쿱으로 수집
			• 구조화하기 어려운 데이터(하둡으로 넣어야 할 웹 로그, 머신 데이터, sns 데이터 등) 은 플룸 or 카프카 활용하여 수집
		○ HDFS로 원천데이터 수집
		○ 맵리듀스, 스파크, 하이브, 피그 등에서 원천 데이터 변환
		○ 스쿱을 이용하여 EDW로 데이터 이동
		○ 분석 툴이 데이터에 접근 가능 --> EDW & 하둡 데이터 모두 활용하여 분석에 사용
		○ 추가로 워크플로 관리 툴로 처리 과정을 오케스트레이션 할 수 있음
	
## 적용 사례 정의
	1. 데이터 설명
	2. OLTP 스키마
		• ERD와 유사한 모습으로 OLTP 표현
		• 목적 : 데이터 정규화 (데이터 중복을 줄이기, 데이터 무결성 보장)
	3. 데이터 웨어하우스 : 소개와 용어
		a. 차원모델링(dimensional = star schema) 
			• 관계형 데이터베이스를 사용하여 다차원 모델 설계 가능
			• 사실 테이블 (factor table)
			• 차원 테이블 (dimension table) 
		b. 정규화 모델 : Key 기준으로 join 하여 데이터 생성
		c. 다차원 모델 설계에 관한 기초 내용
			i. Grain (그레인) : 팩트 테이블에 존재하는 데이터의 상세 정도 수준
			ii. Additivity (합산가능) : 팩트를 합산하거나 평균냄
			iii. 집계한 팩트 테이블 : 집계 테이블 쿼리 속도 향상을 위해 팩트 테이블을 rollup한 테이블
			iv. 팩트 테이블 : 차원테이블과 연결하는 FK(외래 키)를 한 개 이상 소유
			v. 디멘션 테이블(=차원테이블) : 모든 쿼리의 제약조건의 원천, 리포트의 레이블
			vi. 달력 디멘션 : mst_calender 같은 것
			vii. 점진적 변경 디멘션 (Slowly Changing dimention)
				□ 기존 데이터의 값 변경 = 집계 테이블 재 생성 --> mst_part
				□ 새로운 행 추가 = 과거이력 변경x  --> mst_part_his
	4. 하둡으로 데이터 웨어하우스 구축
		• 매일 OLTP 데이터 베이스에 저장되어 있는 데이터와 동일한 데이터 저장
	5. 상위 수준 설계
		• OVERWITE (덮어쓰기)
		• Incremental imports (증분 가져오기) : 증가한 부분만 가져오기, 2가지 케이스 존재
			i. 증분가져오기
			ii. 수정사항 merge

## 데이터 모델링과 스토리지
	1. 스토리지 엔진 선택하기 : 데이터 접근 패턴에 따라 선택
		a. HDFS 
		b. Hbase
	2. 반정규화 (denormalizing)
		• 데이터 조회 성능을 높이기 위해 정규화된 데이터를 통합하는 모델링 기법
		• Join 하는 테이블이 작을 경우 적합 --> 공통코드 등 
		• 테이블의 수정이 많이 발생하지 않을 경우 적합 
	3. 하둡에서 변경사항 추적 및 저장
		a. 변경 사항을 append만 하는 history 테이블 생성 - 수정일자를 포함하여 관리
		b. 해당 factor에 대해 최신 데이터만 존재하는 테이블 생성
	4. 스토리지 포맷과 압축 선택 
		a. 저장
			i. 애브로
				1) 스키마의 변화 지원 -> OLTP 스키마가 변경되어도 ETL은 중단되지 않음
				2) ROW 기반으로 저장하는 경우 (append가 많은 경우)
			ii. 파케이 
				1) 성능이 가장 좋음 
					a) 칼럼너포맷으로 사용하지 않는 칼럼의 데이터가 포함된 블록은 건너뛰어 조회
					b) 압축률이 가장 좋음
				2) 컬럼 기반으로 저장할 경우 ( 컬럼이 많은 테이블 )
				3) 추천 블록 사이느 256MB 보다 10배 이상 크지 않은 경우는 애브로가 적합
		b. 압축 : 스내피를 가장 많이 사용
	5. 파티셔닝
		a. 검색 조건이 되는 칼럼을 기준으로 파티셔닝
		b. 파티션의 평균 크기는 최소한 HDFS 블록 크기의 몇 배 정도가 되어야함 --> 그 이하면 파티셔닝X
	6. 수집 (스쿱)
		• 스쿱을 이용하여 관계형 데이터베이스에서 하둡으로 데이터를 수집 (변경 데이터 추출 시스템, CDC 사용 가능)
		• 테이블의 유형 별 처리 방법
			i. 잘 변화하지 않는 테이블
			ii. 정기적으로 변화하지만 상대적으로 작은 테이블
				• 매일 모든 데이터를 추출하여 하둡에 넣음
			iii. 정기적으로 변화하고 매일 전체를 추출해야 하는 테이블
				• 수정사항만을 추출해 하둡에 반영
		• Join 옵션
			i. 스쿱 작업 내에서 조인 : SQL쿼리가 단순하며, OLTP 데이터베이스의 자원이 충분할 경우
			ii. 하둡에서 조인 : 전체 테이블을 한번 추출하고 파티션으로 구성한 하이브 테이블 생성 후 최근 데이터 append or 병합
		• 증분 임포트를 사용하기 위한 방법
			i. 스쿱 메타스토어를 생성해야함
			ii. 팩트 테이블 파티션
			iii. 새롭게 수정된 데이터 기존 테이블에 병합

## 데이터 프로세싱과 액세스
	1. 파티셔닝
		a. 기존 테이블 파티셔닝
		b. 테이블의 다수 파티션으로 데이터 적재
		c. 테이블의 신규 파티션으로 디렉터리에 데이터를 임포트하여 데이터 추가
	2. 병합/업데이트
		a. 관리 기간의 데이터를 포함하고 있는 파티션만 복제하여 수정
		b. 클러스터 노드 추가
		c. 빠르게 변화하는 테이블은 Hbase에 저장
		• INSERTOVERWRITE 연산은 하이브에서 논-아토믹(non-atomic) -> 사용자가 동일 테이블에서 다른 데이터를 볼 수 있음 ==> 임시테이블을 생성하여 비교하는 방식으로 해결
	3. 집계
	
